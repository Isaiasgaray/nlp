{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16951d73-b163-49ee-9590-c6e32bed6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f563782-1ebc-4956-a3c4-c5c8d06216c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capital = pd.read_csv('datasets/lacapital.csv')\n",
    "\n",
    "df_capital.dropna(inplace=True)\n",
    "\n",
    "df_norm = df_capital.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c1432-fdc8-4886-8411-7332074f4117",
   "metadata": {},
   "source": [
    "# Limpieza y normalización de texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b67fbb-31bd-4498-a20e-6916d4b162e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/isaias/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/isaias/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "stop_words_extra = ['año', 'años', 'dos', 'tres', 'si', 'sí']\n",
    "\n",
    "for word in stop_words_extra:\n",
    "    stop_words.add(word)\n",
    "\n",
    "def remove_accents(input_str):\n",
    "  nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "  return ''.join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  word_tokens = word_tokenize(text)\n",
    "  filtered_text = [word for word in word_tokens if word.casefold() not in stop_words]\n",
    "  return \" \".join(filtered_text)\n",
    "\n",
    "for col in df_capital.columns[:-2]:\n",
    "    df_norm[col] = df_norm[col].str.lower()\n",
    "    df_norm[col] = df_norm[col].str.replace('[^\\w\\s]', '', regex=True)\n",
    "    df_norm[col] = df_norm[col].apply(remove_stopwords)\n",
    "    df_norm[col] = df_norm[col].apply(remove_accents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec015b8d-62d9-432b-9fb3-0c18d8474a1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ad6755-6f5e-46a0-9aee-7e21e67a19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ovación                  57\n",
       "Política                 48\n",
       "La Ciudad                32\n",
       "Zoom                     31\n",
       "Policiales               22\n",
       "Información General      17\n",
       "Economía                 16\n",
       "La Región                16\n",
       "Mundial de Rugby 2023     8\n",
       "El Mundo                  6\n",
       "Educación                 4\n",
       "Turismo                   4\n",
       "Negocios                  2\n",
       "La región                 2\n",
       "Cristina                  1\n",
       "Opinión                   1\n",
       "Julián Montoya            1\n",
       "Baby Etchecopar           1\n",
       "Colón                     1\n",
       "Pepín rodríguez simón     1\n",
       "Name: categoria, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capital['categoria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7364b6-bd5f-4f82-a021-135a203134ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = df_norm['categoria'].value_counts()\n",
    "categorias = categorias[categorias >= 10].index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5311daef-bb5f-49b3-a7e9-6d9b95906801",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_df = list()\n",
    "\n",
    "for categoria in categorias:\n",
    "    temp_df = df_norm[df_norm['categoria'] == categoria]\n",
    "    categorias_df.append(temp_df.sample(22, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe5b83ff-02f3-4e14-947b-02639f431386",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "y = list()\n",
    "\n",
    "for df in categorias_df:\n",
    "    x += df['titulo'].tolist()\n",
    "    y += df['categoria'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf6a078-ab6e-46ec-bd0a-a5d7cf8e1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbff3422-f65b-49ca-8c53-d08a729dc82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ab1e39-1920-4b19-819e-8e5ce81b558e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_train_vectorized = vectorizer.fit_transform(x_train)\n",
    "x_test_vectorized = vectorizer.transform(x_test)\n",
    "\n",
    "modelo_LR = LogisticRegression(max_iter=1000)\n",
    "modelo_LR.fit(x_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b25b018d-9f47-4f87-bb80-84edd91782f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LR = modelo_LR.predict(x_test_vectorized)\n",
    "acc_LR = accuracy_score(y_test, y_pred_LR)\n",
    "report_LR = classification_report(y_test, y_pred_LR, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "465681dd-97bd-4195-aed2-955801001091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Regresión Logística: 0.5454545454545454\n",
      "Reporte de clasificación Regresión Logística:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      ciudad       1.00      0.40      0.57         5\n",
      "     ovacion       0.18      1.00      0.31         2\n",
      "  policiales       1.00      0.44      0.62         9\n",
      "    politica       0.67      0.67      0.67         3\n",
      "        zoom       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.55        22\n",
      "   macro avg       0.77      0.64      0.59        22\n",
      "weighted avg       0.88      0.55      0.61        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisión Regresión Logística:\", acc_LR)\n",
    "print(\"Reporte de clasificación Regresión Logística:\\n\", report_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d510626-dec2-4508-8df3-f019037fa096",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "584cb510-8551-4d64-9eff-58a799c79c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9059a214-324e-40fd-b359-f6a28b9eac12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, categoria \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(categorias):\n\u001b[1;32m      4\u001b[0m     texto \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df_norm[df_norm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategoria\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m categoria][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexto\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m     wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m----> 9\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmin_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(wordcloud)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfrequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# find font sizes\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    505\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[1;32m    506\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[1;32m    510\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[1;32m    511\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[1;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[0;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[1;32m    669\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(font, ImageFont\u001b[38;5;241m.\u001b[39mFreeTypeFont):\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supported for TrueType fonts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    672\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[1;32m    673\u001b[0m bbox \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mgetbbox(\n\u001b[1;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[1;32m    675\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "for idx, categoria in enumerate(categorias):\n",
    "    texto = ' '.join(df_norm[df_norm['categoria'] == categoria]['texto'])\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=900,\n",
    "                            background_color='white',\n",
    "                            stopwords=None,\n",
    "                            min_font_size=10).generate(texto)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, idx + 1)\n",
    "    ax.imshow(wordcloud)\n",
    "    plt.title(f'{categoria.capitalize()}', fontsize=40)\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae10550-741b-4e16-aaab-5737d91c667d",
   "metadata": {},
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89191aa-f1c3-4051-b095-27a1fac3717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model     = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dc6aafa-ca32-49a0-8fa5-cf8004c9861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovacion_norm = df_norm[df_norm['categoria'] == 'ovacion'][:22]\n",
    "ovacion      = df_capital[df_capital['categoria'] == 'Ovación'][:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969d1ce-e887-43b3-bf31-886a8e3b146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovacion['titulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea740a-2a69-49b9-a454-fda143a424d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_embeddings(df, col, n=None):\n",
    "    \n",
    "    embeddings_list = list()\n",
    "\n",
    "    if n == None:\n",
    "        n = len(df)\n",
    "\n",
    "    for title in df[col][:n]:\n",
    "        tokens = tokenizer.tokenize(title)\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        token_ids = torch.tensor([token_ids])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(token_ids)\n",
    "            embeddings = outputs.last_hidden_state\n",
    "\n",
    "        embeddings_list.append(embeddings[0])\n",
    "        \n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d71bb-3ed7-4dcc-9cf9-4f41f4e90dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = crear_embeddings(ovacion_norm, 'titulo')\n",
    "b = crear_embeddings(ovacion, 'titulo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6c0df-74f4-40b3-bd5e-e66e9d0c6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovacion['titulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb9458-9c56-4508-860f-2610e2164236",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(a[0].mean(dim=0).unsqueeze(0), a[3].mean(dim=0).unsqueeze(0))\n",
    "print(f\"Similitud entre la primera y segunda oración: {similarity.item()}\")\n",
    "\n",
    "similarity = cosine_similarity(a[0].mean(dim=0).unsqueeze(0), a[2].mean(dim=0).unsqueeze(0))\n",
    "print(f\"Similitud entre la primera y tercera oración: {similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e1d79-2517-4ac3-8ea7-b00b4faf2a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos_ovacion = []\n",
    "\n",
    "for ii in ovacion_norm.titulo:\n",
    "  titulos_ovacion.append(ii)\n",
    "\n",
    "embeddings_list = []\n",
    "\n",
    "for sentence in titulos_ovacion:\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    token_ids = torch.tensor([token_ids])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(token_ids)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "\n",
    "    embeddings_list.append(embeddings[0])\n",
    "\n",
    "\n",
    "similarity = cosine_similarity(embeddings_list[0].mean(dim=0).unsqueeze(0), embeddings_list[6].mean(dim=0).unsqueeze(0))\n",
    "print(f\"Similitud entre la primera y segunda oración: {similarity.item()}\")\n",
    "\n",
    "similarity = cosine_similarity(embeddings_list[0].mean(dim=0).unsqueeze(0), embeddings_list[21].mean(dim=0).unsqueeze(0))\n",
    "print(f\"Similitud entre la primera y tercera oración: {similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e8177-add1-4955-8f1d-d9451969c771",
   "metadata": {},
   "source": [
    "# Ejercicio 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcc128ac-842b-47f1-955b-61f6cf70b32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rosario fue elegida para realizar el primer encuentro provincial de ligas sub-12 en el fútbol femenino, que se realizará este sábado a partir de las 10 y se llevará a cabo en el predio de la Asociación Rosarina de Fútbol, exBatallón 121, ubicado en Ayacucho al 5000, muy cerca del Museo del Deporte. El encuentro contará con 7 asociaciones oficiales: Santafesina, Rosarina A y B, Casildense, Rafaelina, Esperancina, Sanlorencina y San Martín. Los partidos serán para compartir, disfrutar y con el objetivo de que sea una jornada recreativa histórica. La entrada será gratuita.\\nLa modalidad de la misma será de la siguiente manera: cada equipo contará con un plantel de 18 jugadoras de las categorías 2012. Vale aclarar que serán 9 titulares y luego se podrán realizar variantes.\\nLa duración de los partidos será de 30 minutos y los cambios se realizarán a los 15 minutos. Se permitirá la sustitución de las 9 jugadoras que iniciaron el juego. Por último cabe mencionar que los compromisos se jugarán de manera simultánea, ya que el predio cuenta con varias canchas.\\nLa Asociación Rosarina tendrá dos equipos y estas fueron las convocadas para el encuentro santafesino:\\nGrupo Azul:\\nUma Albornoz, Telma Barile, Luisina Ottaviano, Milagros Csagrande, Guadalupe Ceraldi,Juana Broin, Tatiana Colaci, Ruth Díaz, Milena Flores, Celeste García, Priscila Goy, Martina Gramajo, Agustina Herrera, Malena Parra, Giuliana Robles, Juana Scala y Julia Viera.\\nGrupo Rojo:\\nEugenia Andino, Alma Badur, Ibel Baéz, Julia Colella, Mia Colere, Jazmín De Nicola Forte, Luisina Doldan, Geraldine Fernández, Luisana Gómez, Bianca López, Julia Magnin, Alma Quintero, Luz y Maia Rodríguez, Denise Salinas, Sabrina Torres, Jazmín Truant y Olivia Ungaro\\nCuerpo técnico:\\nJosefina Silva, Dina Goffi, Valentina Viola, Mayra Mansilla y Rodrigo Mastrogiuseppe.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovacion['texto'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b1776-085f-4ce8-bfaf-276816dceae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar el modelo de spaCy\n",
    "# !python -m spacy download es_core_news_md\n",
    "nlp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b0bf6-922b-4b67-94df-64c3a7bf6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(noticia)\n",
    "\n",
    "# Función para generar un resumen extractivo usando PageRank\n",
    "def summarize(text, num_sentences=5):\n",
    "    \n",
    "    lemmatized_sentences = list()\n",
    "    original_sentences   = list()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        lemmatized_sentence = ' '.join(\n",
    "                                        token.lemma_ for token in sent\n",
    "                                        if not token.is_stop and \n",
    "                                        not token.is_punct)\n",
    "\n",
    "        if lemmatized_sentence.strip() != '':\n",
    "            lemmatized_sentences.append(lemmatized_sentence)\n",
    "            original_sentences.append(str(sent).strip())\n",
    "\n",
    "    # Procesar las oraciones lematizadas con spaCy para obtener sus vectores\n",
    "    lemmatized_docs = [nlp(sent) for sent in lemmatized_sentences]\n",
    "\n",
    "    # Obtenemos una lista con los vectores de cada oración\n",
    "    sentence_vectors = [sent.vector for sent in lemmatized_docs]\n",
    "\n",
    "    # Devuelve una matriz de similitud entre las oraciones filtradas\n",
    "    similarity_matrix = cosine_similarity(sentence_vectors)\n",
    "    \n",
    "    # Crear un grafo a partir de la matriz de similitud\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    \n",
    "    # Aplicar PageRank al grafo\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    # Ordenar las oraciones por su puntuación y seleccionar las mejores\n",
    "    ranked_sentences = sorted(\n",
    "                            (\n",
    "                                (scores[i], s) for i, s\n",
    "                                in enumerate(original_sentences)\n",
    "                            ),\n",
    "                            reverse=True)\n",
    "    \n",
    "    return ' '.join(ranked_sentences[i][1] for i in range(num_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef36ed-73a7-42cf-aa4a-528af8ee361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen = summarize(noticia, num_sentences=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539b7e6-f200-41ea-a4db-4a01103e9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc07866b-23fb-4bf0-94dc-4b3b49333ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rosario fue elegida para realizar el primer encuentro provincial de ligas sub-12 en el fútbol femenino, que se realizará este sábado a partir de las 10 y se llevará a cabo en el predio de la Asociación Rosarina de Fútbol, exBatallón 121, ubicado en Ayacucho al 5000, muy cerca del Museo del Deporte. El encuentro contará con 7 asociaciones oficiales: Santafesina, Rosarina A y B, Casildense, Rafaelina, Esperancina, Sanlorencina y San Martín. Los partidos serán para compartir, disfrutar y con el objetivo de que sea una jornada recreativa histórica. La entrada será gratuita.\\nLa modalidad de la misma será de la siguiente manera: cada equipo contará con un plantel de 18 jugadoras de las categorías 2012. Vale aclarar que serán 9 titulares y luego se podrán realizar variantes.\\nLa duración de los partidos será de 30 minutos y los cambios se realizarán a los 15 minutos. Se permitirá la sustitución de las 9 jugadoras que iniciaron el juego. Por último cabe mencionar que los compromisos se jugarán de manera simultánea, ya que el predio cuenta con varias canchas.\\nLa Asociación Rosarina tendrá dos equipos y estas fueron las convocadas para el encuentro santafesino:\\nGrupo Azul:\\nUma Albornoz, Telma Barile, Luisina Ottaviano, Milagros Csagrande, Guadalupe Ceraldi,Juana Broin, Tatiana Colaci, Ruth Díaz, Milena Flores, Celeste García, Priscila Goy, Martina Gramajo, Agustina Herrera, Malena Parra, Giuliana Robles, Juana Scala y Julia Viera.\\nGrupo Rojo:\\nEugenia Andino, Alma Badur, Ibel Baéz, Julia Colella, Mia Colere, Jazmín De Nicola Forte, Luisina Doldan, Geraldine Fernández, Luisana Gómez, Bianca López, Julia Magnin, Alma Quintero, Luz y Maia Rodríguez, Denise Salinas, Sabrina Torres, Jazmín Truant y Olivia Ungaro\\nCuerpo técnico:\\nJosefina Silva, Dina Goffi, Valentina Viola, Mayra Mansilla y Rodrigo Mastrogiuseppe.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
